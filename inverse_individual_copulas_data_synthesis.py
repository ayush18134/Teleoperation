# -*- coding: utf-8 -*-
"""inverse_individual_copulas_data_synthesis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e9oygCfnIBs1iMWJ3KjjOil7j1OKlugD

## Install Dependencies
"""

!pip install numpy
!pip install copulas
!pip install table-evaluator
!pip install pyCompare

"""##Dataset Class"""

#Dataset format - Pandas Dataframe
#Rows are the participants
#Columns are time to completion, number of collisions, number of dropped objects and Spatial ability scores

import pandas as pd
import numpy as np
temp=[233,190,286,445,281,260,301,322,245,418,164,278,309,309]
class Dataset():
    def getData(self):
        dataset = pd.DataFrame(np.array([[ 233, 2.0, 0.8, 68.0],
                                         [ 190, 0.2, 0.0, 70.4],
                                         [ 286, 0.4, 0.0, 58.4],
                                         [ 445, 4.6, 3.0, 52.0],
                                         [ 281, 1.8, 0.6, 65.6],
                                         [ 260, 2.3, 0.8, 80.0],
                                         [ 301, 0.6, 1.0, 64.0],
                                         [ 322, 2.8, 1.2, 52.0],
                                         [ 245, 2.0, 0.0, 88.0],
                                         [ 418, 2.3, 0.7, 57.0],
                                         [ 164, 0.6, 0.2, 65.0],
                                         [ 278, 0.6, 0.0, 87.0],
                                         [ 309, 1.2, 0.8, 53.0],
                                         [ 309, 0.0, 0.3, 84.0]]), columns = [ 'Total Time', 'Number of collisions', 'Number of Dropped Objects', 'Spatial Ability'])
        self.dataset = dataset
        return dataset.iloc[:, 1:]

    def getScaledData(self):
        dataset = self.getDataset()
        for col in dataset:
            dataset[col] = dataset[col] / np.max(dataset[col])
        return dataset

"""## Synthesize Data"""

from copulas.multivariate import GaussianMultivariate
from copulas.visualization import compare_3d

dataset = Dataset()
real_data = dataset.getData()


# Initiates the Copulas and call its fit method to pass in the table
copula = GaussianMultivariate()
# copula = VineCopula('regular') # center, regular, direct
copula.fit(real_data)

# print(real_data.to_string())

# Generate synthetic data
synthetic_data = copula.sample(10000)
# print(synthetic_data.to_string())

# Plot the real and the synthetic data to compare
compare_3d(real_data, synthetic_data)

"""## Verify Obtained data"""

from table_evaluator import TableEvaluator

table_evaluator = TableEvaluator(real_data, synthetic_data)
table_evaluator.visual_evaluation()

"""## Data Preparation"""

import numpy as np
from sklearn.metrics import mean_squared_error, r2_score
import pyCompare

synthetic_data=synthetic_data[(synthetic_data> 0).all(1)].reset_index(drop=True)

trainX=[]
trainY=[]
testX=[]
testY=[]

# Combination 1 - Combine synthetic and real data to form test and train datasets
# Adding 4 rows of real data in training set
synthetic_data_new=np.array(synthetic_data)
real_data = np.array(real_data)
for i in range(4):
    testY.append([real_data[i][0],real_data[i][1]])
    testX.append(real_data[i][2])
# Adding 10 rows of real data in testing set
for i in range(4,len(real_data)):
    trainY.append([real_data[i][0],real_data[i][1]])
    trainX.append(real_data[i][2])
# Adding 80% rows of synthetic data in training set
for i in range(int(len(synthetic_data_new)/5)):
    testY.append([synthetic_data_new[i][0],synthetic_data_new[i][1]])
    testX.append(synthetic_data_new[i][2])
# Adding 20% rows of synthetic data in training set
for i in range(int(len(synthetic_data_new)/5),len(synthetic_data_new)):
    trainY.append([synthetic_data_new[i][0],synthetic_data_new[i][1]])
    trainX.append(synthetic_data_new[i][2])

#Combination 2 - Use synthetic as train and real as test
# trainY = synthetic_data.iloc[:, :-1]
# trainX = synthetic_data.iloc[:, -1]

# testY = real_data.iloc[:, :-1]
# testX = real_data.iloc[:, -1]

trainX = np.array(trainX)
trainY = np.array(trainY)
testX = np.array(testX)
testY = np.array(testY)

trainX = trainX.reshape(trainX.shape[0], 1)
testX = testX.reshape(testX.shape[0], 1)

"""## Models

### Elastic Net
"""

from sklearn.linear_model import ElasticNet
import numpy as np
model = ElasticNet()
model.fit(trainX, trainY)
print(model.score(trainX, trainY))
print(model.score(testX, testY))

predictedData = model.predict(trainX)
# print(predictedData)
predictedData = model.predict(testX)
# print(predictedData)

"""### Linear Regression"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.multioutput import RegressorChain, MultiOutputRegressor

regr = linear_model.LinearRegression()
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = linear_model.LinearRegression()
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

testXFlat = testX.flatten()
predictedData2Flat = predictedData2.flatten()

pyCompare.blandAltman(testXFlat, predictedData2Flat)

"""### SVM Regression"""

from sklearn.svm import SVR
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.multioutput import RegressorChain, MultiOutputRegressor
import numpy as np

regr = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))
# regr = SVR()
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())


testXFlat = testX.flatten()
predictedData2Flat = predictedData2.flatten()

pyCompare.blandAltman(testXFlat, predictedData2Flat)

"""### KNN"""

from sklearn.neighbors import KNeighborsRegressor
regr = KNeighborsRegressor(n_neighbors=2)
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = KNeighborsRegressor(n_neighbors=2)
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

testXFlat = testX.flatten()
predictedData2Flat = predictedData2.flatten()

pyCompare.blandAltman(testXFlat, predictedData2Flat)

"""### Random Forest"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.datasets import make_regression

regr = RandomForestRegressor(random_state=0, max_depth=20)
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = RandomForestRegressor(random_state=0, max_depth=20)
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

testXFlat = testX.flatten()
predictedData2Flat = predictedData2.flatten()

pyCompare.blandAltman(testXFlat, predictedData2Flat)

"""### MLP"""

from sklearn.neural_network import MLPRegressor
from sklearn.datasets import make_regression
regr = MLPRegressor(random_state=1, max_iter=500)
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = MLPRegressor(random_state=1, max_iter=500)
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

testXFlat = testX.flatten()
predictedData2Flat = predictedData2.flatten()

pyCompare.blandAltman(testXFlat, predictedData2Flat)

"""### Gradient Boosting Regressor"""

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.multioutput import RegressorChain, MultiOutputRegressor

regr = GradientBoostingRegressor()
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = GradientBoostingRegressor()
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())


testX = testX.flatten()
predictedData2 = predictedData2.flatten()

pyCompare.blandAltman(predictedData2, testX)

"""### ADA Boost"""

from sklearn.ensemble import AdaBoostRegressor
from sklearn.multioutput import RegressorChain, MultiOutputRegressor

regr = AdaBoostRegressor()
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = AdaBoostRegressor()
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

"""### Decision Tree Regressor"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.multioutput import RegressorChain, MultiOutputRegressor

regr = DecisionTreeRegressor(max_depth = 25 ,criterion='mse') #, min_samples_leaf=5, min_samples_split=4
regr = MultiOutputRegressor(regr)
regr.fit(trainX, trainY)

regr2 = DecisionTreeRegressor(max_depth = 25 ,criterion='mse') #, min_samples_leaf=5, min_samples_split=4
regr2.fit(trainY, trainX)

# For training Data
predictedData = regr.predict(trainX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - trainX)) / trainX) * 100

percentChange = {}
for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / trainX.shape[0]) * 100

print(percentChange.values())

# For testing Data
predictedData = regr.predict(testX)
predictedData2 = regr2.predict(predictedData)

percDiff = ((np.abs(predictedData2 - testX)) / testX) * 100

percentChange = {}

for i in range(5, 100, 5):
    percentChange[i] = ((np.sum(percDiff[:, 0] < i)) / testX.shape[0]) * 100

print(percentChange.values())

"""### StatsModel"""